# TASs ( Request Flow â³)
User clicks "Buy"â¬‡ï¸

Load Balancer
â¬‡ï¸

TSAS receives request
â¬‡ï¸

Classify request
â¬‡ï¸

Check rate limits
â¬‡ï¸

Check backend capacity
â¬‡ï¸

(ðŸ§ Logic)
If free â†’ dispatch immediatelyðŸ”€ï¸
Else â†’ enqueue ðŸ”„


Worker sends request to backend
â¬‡ï¸ï¸

Backend processes request
â¬‡ï¸ï¸

Response flows back to user ðŸ‘†ðŸ¼â¬†ï¸

#______________________After Inplemetation___________________

# TAS â€“ Traffic Acquisition System

A high-performance backend system built with **Spring Boot** that handles traffic spikes using rate limiting, async request queuing, and real-time monitoring. Designed to simulate how large-scale platforms (like Flipkart or Amazon) protect their backend during flash sales.

---

## How It Works

Incoming requests pass through three layers of protection:

```
Request â†’ TrafficMonitor â†’ RateLimiter â†’ RequestQueue â†’ BuyService
              â†“                 â†“               â†“
          Count RPS         Block if >10     Queue if busy
```

1. **TrafficMonitor** â€” counts requests per second using thread-safe `AtomicInteger` with CAS-based window reset
2. **RateLimiter** â€” rejects requests that exceed the configured threshold (HTTP 429)
3. **RequestQueue** â€” queues accepted requests into a `BlockingQueue`, processed async by a fixed thread pool

---

## API Endpoints

| Method | Endpoint | Description | Success Code |
|--------|----------|-------------|--------------|
| `POST` | `/api/v1/buy` | Submit a buy request | `202 Accepted` |
| `GET` | `/api/v1/queue/size` | Current queue depth | `200 OK` |
| `GET` | `/api/v1/metrics` | Full system metrics snapshot | `200 OK` |
| `GET` | `/api/v1/health` | Health status (UP / DEGRADED) | `200 OK` |

### Response Codes
| Code | Meaning |
|------|---------|
| `202` | Request accepted and queued |
| `429` | Rate limit exceeded â€” too many requests/sec |
| `503` | Queue full â€” server busy, try again |
| `500` | Internal server error |

### Sample `/metrics` Response
```json
{
  "success": true,
  "message": "Metrics retrieved",
  "data": {
    "currentRps": 4,
    "currentRpm": 52,
    "totalRequests": 200,
    "totalRejected": 12,
    "rejectionRatePercent": 6.0,
    "queueSize": 8,
    "maxQueueSize": 50,
    "queueProcessed": 188,
    "queueDropped": 0,
    "rateLimitMaxRps": 10,
    "status": "HEALTHY"
  }
}
```

---

## Run Locally

### Prerequisites
- Java 17+
- Maven 3.8+

### Steps

```bash
# 1. Clone the repo
git clone https://github.com/your-username/tas-system.git
cd tas-system

# 2. Build
mvn clean install

# 3. Run
mvn spring-boot:run
```

Server starts at `http://localhost:8080`

### Test it
```bash
# Submit a buy request
curl -X POST http://localhost:8080/api/v1/buy

# Check metrics
curl http://localhost:8080/api/v1/metrics

# Check health
curl http://localhost:8080/api/v1/health
```

---

## Configuration

All values are tunable in `application.properties` â€” no code changes needed:

```properties
# Max requests allowed per second before throttling
tas.rate-limit.max-rps=10

# Max requests that can wait in queue
tas.queue.max-size=50

# Number of parallel worker threads
tas.queue.thread-pool-size=5
```

---

## Project Structure

```
com.Tas.TAS/
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ BuyController.java       # POST /buy, GET /queue/size
â”‚   â””â”€â”€ MetricsController.java   # GET /metrics, GET /health
â”œâ”€â”€ limiter/
â”‚   â””â”€â”€ RateLimiter.java         # Per-second rate throttling
â”œâ”€â”€ monitor/
â”‚   â””â”€â”€ TrafficMonitor.java      # Thread-safe RPS/RPM tracking
â”œâ”€â”€ queue/
â”‚   â””â”€â”€ RequestQueue.java        # Async bounded queue + thread pool
â”œâ”€â”€ service/
â”‚   â””â”€â”€ BuyService.java          # Business logic (purchase processing)
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ ApiResponse.java         # Unified JSON response wrapper
â”‚   â””â”€â”€ MetricsSnapshot.java     # Metrics data model
â””â”€â”€ exception/
    â””â”€â”€ GlobalExceptionHandler.java  # Centralized error handling
```

---

### What problem does this solve?
During a flash sale, thousands of requests hit `/buy` simultaneously. Without protection, the server crashes. This system handles that with three layers: count traffic, reject excess, queue the rest.

### Key technical concepts used
- **`AtomicInteger` / `AtomicLong`** â€” thread-safe counters without synchronized blocks
- **CAS (Compare-And-Swap)** â€” used in `compareAndSet()` to safely reset the per-second window with no race condition
- **`BlockingQueue`** â€” producer-consumer pattern; HTTP thread produces tasks, worker pool consumes them
- **`ExecutorService`** with named threads â€” parallel async processing, easier to debug in logs
- **Graceful shutdown** â€” `@PreDestroy` drains the queue before the app stops

### Why not just use Kubernetes?
Kubernetes autoscaling **reacts** â€” it sees a CPU spike, then spins up new pods. That takes 30â€“60 seconds. A flash sale crushes your server in the first 5 seconds. This rate limiter and queue respond in **microseconds**. You need both: K8s for horizontal scaling, this for application-level protection while scaling happens.

### Design patterns used
- **Producer-Consumer** â€” HTTP thread produces, worker pool consumes
- **Chain of Responsibility** â€” Monitor â†’ RateLimiter â†’ Queue, each layer can reject
- **Facade** â€” Controller hides all complexity behind a single `/buy` endpoint

### we will add next? (coming up)
- Replace in-memory queue with **Kafka** for distributed scaling across pods
- Add **Resilience4j** circuit breaker for downstream failures
- **Prometheus + Grafana** dashboard off the `/metrics` endpoint
- **JUnit load tests** using `CountDownLatch` to simulate concurrent traffic
